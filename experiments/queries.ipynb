{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dir to root\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "from core import OfferDBSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = OfferDBSession()\n",
    "offers = db.get_rows()\n",
    "df = pd.DataFrame(offers)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retailers = set(df.RETAILER.unique())\n",
    "retailers.remove(\"\")\n",
    "\n",
    "r_scores = [(df.RETAILER == retailer).astype(int).to_list() for retailer in retailers ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = set(df.BRAND.unique())\n",
    "b_scores = [(df.BRAND == brand).astype(int).to_list() for brand in brands ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = set()\n",
    "for cats in df.CATEGORIES:\n",
    "    categories.update(json.loads(cats))\n",
    "c_scores = []\n",
    "for category in categories:\n",
    "    scores = []\n",
    "    for cats in df.CATEGORIES:\n",
    "        score = 1 if category in json.loads(cats) else 0\n",
    "        scores.append(score)\n",
    "    c_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_categories = set()\n",
    "for cats in df.SUPER_CATEGORIES:\n",
    "    super_categories.update(json.loads(cats))\n",
    "sc_scores = []\n",
    "for category in super_categories:\n",
    "    scores = []\n",
    "    for cats in df.SUPER_CATEGORIES:\n",
    "        score = 1 if category in json.loads(cats) else 0\n",
    "        scores.append(score)\n",
    "    sc_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(retailers), len(r_scores))\n",
    "print(len(brands), len(b_scores))\n",
    "print(len(categories), len(c_scores))\n",
    "print(len(super_categories), len(sc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = list(retailers) + list(brands) + list(categories) + list(super_categories)\n",
    "types = [\"retailer\"] * len(retailers) + [\"brand\"] * len(brands) + [\"category\"] * len(categories) + [\"super category\"] * len(super_categories)\n",
    "scores = r_scores + b_scores + c_scores + sc_scores\n",
    "# scores = [json.dumps(score) for score in scores]\n",
    "\n",
    "gold_scores = pd.DataFrame({'QUERY': queries, 'TYPE': types, 'SCORES': scores})\n",
    "gold_scores = gold_scores.sort_values(['TYPE', 'QUERY']).reset_index()\n",
    "gold_scores.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_scores.to_csv('./data/processed/true_scores_gold.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "def complete(model_name, sys_prompt, user_prompt, pbar, temperature = 0, top_p = 1):\n",
    "\n",
    "    MAX_API_RETRY = 5\n",
    "    for i in range(MAX_API_RETRY):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": user_prompt,\n",
    "                    },\n",
    "                ],\n",
    "                temperature= temperature,\n",
    "                top_p = top_p,\n",
    "            )\n",
    "            content = response.choices[0].message.content\n",
    "\n",
    "            return content\n",
    "        except Exception as e:\n",
    "            pbar.write(f'Error: {e}')\n",
    "            time.sleep(5 * i)\n",
    "\n",
    "    raise RuntimeError('Maximum retries reached\\n')\n",
    "\n",
    "def get_queries(input_type, input_, pbar):\n",
    "    model_name = 'gpt-3.5-turbo'\n",
    "    temperature = 0.2\n",
    "\n",
    "    sys_prompt = 'You are a synthetic search query generator, write 10 natural language queries that a user '\n",
    "    sys_prompt += f'might type or say to find relevant offers for the given {input_type.title()} name.\\n'\n",
    "    sys_prompt += f'4 out of 10 queries should contain possible typos of the {input_type.title()} name.\\n'\n",
    "    sys_prompt += 'Generate queries in json format like - {\"queries\": [\"query1\", ...]}\\n'\n",
    "\n",
    "    match input_type:\n",
    "        case 'retailer':\n",
    "            sys_prompt += 'For example, if the retailer is Amazon, the queries could be:\\n'\n",
    "            sys_prompt += '\"Show me the best deals from Amazon\"\\n'\n",
    "            sys_prompt += '\"amazonn\"'\n",
    "        case 'brand':\n",
    "            sys_prompt += 'For example, if the brand is Huggies, the queries could be:\\n'\n",
    "            sys_prompt += '\"Show me the best deals on Huggies diapers\"\\n'\n",
    "            sys_prompt += '\"hugies\"'\n",
    "        case 'category', 'super category':\n",
    "            sys_prompt += 'For example, if the category is Hair Care, the queries could be:\\n'\n",
    "            sys_prompt += '\"Show me the best deals for Hair Care products\"\\n'\n",
    "            sys_prompt += '\"Har Care\"'\n",
    "\n",
    "    user_prompt = f'{input_type.title()}: {input_.lower()}\\nQueries:'\n",
    "\n",
    "    try:\n",
    "        response = complete(model_name, sys_prompt, user_prompt, pbar, temperature)\n",
    "        response = json.loads(response)\n",
    "        return response\n",
    "    except:\n",
    "        print(f\"Failed:\\t {input_type} = {input_}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.read_csv('./data/processed/true_scores_gold.csv')\n",
    "queries = score_df.QUERY.to_list()\n",
    "types = score_df.TYPE.to_list()\n",
    "syn_queries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(desc=\"Generating...\", total=len(queries), unit='query')\n",
    "for idx, (type_, query) in enumerate(zip(types,queries)):\n",
    "    data = {'index': idx, 'term':query, 'type':type_}\n",
    "    data['queries'] = get_queries(type_,query, pbar).get('queries',[])\n",
    "    syn_queries.append(data)\n",
    "    pbar.update(1)\n",
    "\n",
    "for query in syn_queries:\n",
    "    if len(query['queries']) < 10:\n",
    "        query['queries'] = get_queries(query['type'],query['term'], pbar).get('queries')\n",
    "    if len(query['queries']) > 10:\n",
    "        query['queries'] = query['queries'][0:10]\n",
    "    pbar.write(f\"Count Correction: {query['index']}, {query['term']}, {query['type']}, {len(query['queries'])}\")\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/processed/syn_queries.json','w') as file:\n",
    "    json.dump(syn_queries, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/processed/syn_queries.json','r') as file:\n",
    "    syn_queries = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = []\n",
    "queries = []\n",
    "types = []\n",
    "scores = []\n",
    "for query in syn_queries:\n",
    "    score = score_df[score_df.QUERY==query['term']].SCORES.head(1).tolist()[0]\n",
    "    terms.extend([query['term']]*len(query['queries']))\n",
    "    queries.extend(query['queries'])\n",
    "    types.extend([query['type']]*len(query['queries']))\n",
    "    scores.extend([score]*len(query['queries']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_scores = pd.DataFrame({'TERM':terms, 'QUERY':queries, 'TYPE':types, 'SCORES':scores})\n",
    "syn_scores.to_csv('./data/processed/true_scores_syn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df = pd.read_csv('./data/processed/true_scores_gold.csv')\n",
    "syn_df = pd.read_csv('./data/processed/true_scores_syn.csv')\n",
    "syn_df.drop('TERM', axis=1, inplace=True)\n",
    "scores_df = pd.concat([gold_df, syn_df], ignore_index=True)[['QUERY','TYPE', 'SCORES']]\n",
    "scores_df.to_csv('./data/processed/true_scores.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fetch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
